<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>
        Document
    </title>
    <link rel='stylesheet' href=../../../css/index.css />
    <link rel='stylesheet' href=../../../css/c.css /><link rel='stylesheet' href=../../../css/makefile.css /><link rel='stylesheet' href=../../../css/shell.css /><link rel='stylesheet' href=../../../css/txt.css /><link rel='stylesheet' href=../../../css/xml.css />
    <link rel="icon" href="https://raw.githubusercontent.com/learner-lu/picbed/master/logo.png">
</head>

<body class="light">
    <a href="https://github.com/luzhixing12345/qemu-kvm.git" target="_blank" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <div class="header-navigator"><ul><li><a href="#h1-0">内存虚拟化</a><ul><li><a href="#h2-1">虚拟机内存地址转换</a></li></ul><ul><li><a href="#h2-2">shadow page(软件)</a></li></ul><ul><li><a href="#h2-3">extended page(硬件)</a></li></ul><ul><li><a href="#h2-4">参考</a></li></ul></li></ul></div><div class='markdown-body'><h1 id="h1-0">内存虚拟化</h1><p>内存虚拟化的目标是提供一种方法,使得每个虚拟机都能够访问自己独立的虚拟内存空间,而这些虚拟内存空间背后实际上是由宿主机的物理内存来提供的.在虚拟化环境中,这种管理机制要有效地确保虚拟机之间的内存隔离,同时优化资源使用率.</p><h2 id="h2-1">虚拟机内存地址转换</h2><p>我们先来快速回顾一下操作系统中的地址转换过程, 这对理解虚拟机内存地址转换非常重要</p><p><a data-lightbox="example-1" href="https://raw.githubusercontent.com/learner-lu/picbed/master/20240321222310.png"><img loading="lazy" src="https://raw.githubusercontent.com/learner-lu/picbed/master/20240321222310.png" alt="20240321222310"></a></p><p>一个标准 table walk 如上图所示, CR3 寄存器保存当前进程的根页表地址, linux 中采用 48 位虚拟地址, 4KB 的页面, 4 级页表, 使用虚拟地址[47:39],索引L1级页表,得到L2级页表的页基地址.使用[38:30]索引L2级页表,得到L2级页表的页基址, 最终在L4级页表得到实际物理页面地址,加上页内偏移,可以得到物理地址</p><blockquote><p>详细的内容参见 <a href="https://luzhixing12345.github.io/klinux/articles/mm/%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2/" target="_blank">虚拟地址转换</a>, 这里不再赘述</p></blockquote><p>在Linux这种使用虚拟地址的OS中,虚拟地址经过page table转换可得到物理地址, 如下图所示</p><p><a data-lightbox="example-1" href="https://raw.githubusercontent.com/learner-lu/picbed/master/20240321234343.png"><img loading="lazy" src="https://raw.githubusercontent.com/learner-lu/picbed/master/20240321234343.png" alt="20240321234343"></a></p><p>但是如果这个操作系统是运行在虚拟机上的, 客户端转换得到的物理地址依然只是一个中间的物理地址, 需要再经过 VMM/hypervisor 的转换,才能得到最终的物理地址(Host Phyical Address - HPA). 因此还需要一次地址转换, 如下图所示</p><p><a data-lightbox="example-1" href="https://raw.githubusercontent.com/learner-lu/picbed/master/20240321234716.png"><img loading="lazy" src="https://raw.githubusercontent.com/learner-lu/picbed/master/20240321234716.png" alt="20240321234716"></a></p><p>因此相比之下, 普通的进程只需要一次地址转换 VA-&gt;PA, 但是在虚拟化环境中需要经过三次地址转换</p><ol start="1"><li>首先通过 Guest 的页表将 Guest Virtual Address (GVA)转换为 Guest Physical Address(GPA)</li></ol><ol start="2"><li>GPA 在 Qemu 的实现当中实际上是对应映射到 Host 中一大块 mmap 的内存上的,所以我们还需要将 GPA 再转换为 Host Virtual Address(HVA)</li></ol><ol start="3"><li>最后再通过 Host 上的页表将 HVA 转化为 Host Physical Address(HPA)</li></ol><p><a data-lightbox="example-1" href="https://raw.githubusercontent.com/learner-lu/picbed/master/20241108161015.png"><img loading="lazy" src="https://raw.githubusercontent.com/learner-lu/picbed/master/20241108161015.png" alt="20241108161015"></a></p><p>这一整套流程非常繁重,从而使得虚拟机中内存访问的性能极为低下, 并且传统的IA32架构从硬件上只支持一次地址转换,即由CR3寄存器指向进程第一级页表的首地址,通过MMU查询进程的各级页表,获得物理地址.</p><p>因此为了完成这种二级地址转换, 现代普遍采用两种优化方式, 分别是<b>软件页表虚拟化(shadow page)和硬件页表虚拟化(extended page)</b></p><blockquote style="border-left-color: #1a7f37; background-color: #e5f6ea;"><p><div style="color: #1a7f37;"><img class="icon-tip" loading="lazy" src="../../../img/tip.svg" alt="[!TIP]"> TIP </div> 下文中会出现一些字母的缩写代称</p><ul><li>H 指主机 host</li></ul><ul><li>G 指客户端 guest</li></ul><ul><li>PA 指物理地址 physical address</li></ul><ul><li>VA 指虚拟地址 virtual address</li></ul><ul><li>PT 指页表 page table</li></ul><p>例如对于 Guest OS 内部的进程页表我们称为 gPT(guest Page Table)</p></blockquote><h2 id="h2-2">shadow page(软件)</h2><p>在早期的时候 Intel 硬件对虚拟化并没有很好的支持,因此 Hypervisor 只能先在软件层面进行优化, <b>影子页表</b>(Shadow Page Table)应运而生.</p><p>影子页表的思路非常简单, 既然虚拟化中的多次地址转换开销很大, 那么在 vmm 中直接记录一张<b>映射表</b>, 也称为影子页表 <b>sPT(shadow Page Table)</b>, 这张表记录 gva 到 hpa 的关系, 如下图所示</p><p><a data-lightbox="example-1" href="https://raw.githubusercontent.com/learner-lu/picbed/master/20250226110558.png"><img loading="lazy" src="https://raw.githubusercontent.com/learner-lu/picbed/master/20250226110558.png" alt="20250226110558"></a></p><blockquote style="border-left-color: #1a7f37; background-color: #e5f6ea;"><p><div style="color: #1a7f37;"><img class="icon-tip" loading="lazy" src="../../../img/tip.svg" alt="[!TIP]"> TIP </div> 图中画出的 spt 是一个映射表, 但其实它就是 qemu 管理的一块内存区域, 也是以页表的形式保存管理</p></blockquote><p>以 Intel 为例,由于读写 CR3 寄存器(存放页顶级表指针)的操作是敏感指令,我们的 vmm 可以很轻易地截获这个操作, 并将<b>页表替换为存放 GVA→HPA 映射关系的影子页表</b>,这样就能直接完成由 GVA 到 HPA 的转换过程. 现在翻译虚拟地址时只需要通过 gva 查 spt 就可以直接得到最终的 hpa 地址, <b>原先的三次地址翻译直接被简化到了一次!</b></p><blockquote style="border-left-color: #8250df; background-color: #eee4ff;"><p><div style="color: #8250df;"><img class="icon-important" loading="lazy" src="../../../img/important.svg" alt="[!IMPORTANT]"> IMPORTANT </div> 部分读者可能会感到疑惑, 这个 spt 是如何构建的? spt 需要记录 gva 到 hpa 的映射, 但是按理来说qemu作为一个系统进程应该不知道 hva 到 hpa 的映射的?</p><p>是的, qemu 作为用户态进程确实无法直接访问 hva-&gt;hpa 的映射, 因为本身这部分是操作系统负责的, 但它通过与内核(如 KVM)的协作来实现这一功能, kvm 作为一个内核模块会将这部分信息传递给 qemu (有对应的 kvm api 函数)</p></blockquote><p>这种纯软件的方法虽然能够解决问题, 三次转换变一次当然很好, 那么代价是什么呢?</p><ul><li>首先我们注意到 spt 记录的是 gva 的映射, 也就是说 vmm 需要为每个guest VM中的<b>每个进程的gPT都维护一个对应的sPT</b>, 且不论多虚拟机, 为每一个进程都记录一份 spt 这显然大大增加了内存的开销.</li></ul><ul><li>其次每个进程的页表是不断变化的, 分配/释放内存时都会修改页表, 那么此时 spt 也要跟着同步. qemu 的做法是<ol start="1"><li>首先 qemu 会将gPT本身使用的物理页面设为<b>write protected</b></li></ol><ol start="2"><li>每当gPT有变动的时候(比如添加或删除了一个页表项),就会产生被VMM截获的<b>page fault异常</b></li></ol><ol start="3"><li>重新计算GVA-&gt;HPA的映射,更改sPT中对应的页表项</li></ol></li></ul><p>我们需要为 Guest VM 中的每套页表都独立维护一份影子页表,且需要多次在 VMM 与 VM 间进行切换,这有着不小的开销. 在一些场景下,这种影子页表机制造成的开销可以占到整个VMM软件负载的75%.</p><h2 id="h2-3">extended page(硬件)</h2><p>从软件层面似乎已经是难以有更好的优化的方案了,因此硬件层面的对内存虚拟化的支持便应运而生. 各大CPU厂商相继推出了硬件辅助的内存虚拟化技术,比如Intel的<b>EPT</b>(Extended Page Table)和AMD的NPT(<b>Nested Page Table</b>),它们都能够从硬件上同时支持 GVA-&gt;GPA-&gt;HPA 的两级地址转换的技术.</p><blockquote><p>硬件虚拟化根据 Intel/AMD 的硬件技术有两个名字, 下文介绍 Intel x86 处理器支持的 EPT</p></blockquote><p>整个流程如下图所示</p><p><a data-lightbox="example-1" href="https://raw.githubusercontent.com/learner-lu/picbed/master/20240322111926.png"><img loading="lazy" src="https://raw.githubusercontent.com/learner-lu/picbed/master/20240322111926.png" alt="20240322111926"></a></p><p>首先先看上面一行的绿色虚线, 它代表的是 guest OS 内部完成的 GVA -&gt; GPA 的地址转换过程. guest 使用 gCR3 记录每个进程的页表基地址(物理地址)</p><p>虽然 GVA -&gt; GPA 的页表逐级遍历中会拿到下一级新的 gPA, 到这里虽然已经转换成物理地址,但是由于是客户机物理地址,不等同于宿主机的物理地址,所以并不能直接访问, gPA 都需要经过VMM的翻译才能得到真实的HPA, 需要借助于第二次的转换,也就是EPT的转换</p><p><b>每个guest VM有一个由VMM维护的EPT</b>, 它维护 GPA -&gt; HPA 的映射.</p><blockquote><p>其实,EPT/NPT就是一种扩展的MMU(以下称EPT/NPT MMU),它可以交叉地查找gPT和EPT两个页表</p></blockquote><p>首先它会查找guest VM中CR3寄存器(gCR3)指向的PML4页表,由于gCR3中存储的地址是GPA,因此CPU需要查找nPT来获取gCR3的GPA对应的HPA, 我们称一次nPT的查找过程为一次nested walk. 如果找到了,也就是获得了一级页表的物理首地址后,就可以用对应的索引得到二级页表的GVA.接下来又是通过一次nested walk得到下一级页表的首地址,然后重复上述过程,最终获得该GVA对应的HPA,</p><p>不同于影子页表是一个进程需要一个sPT,EPT/NPT MMU解耦了GVA-&gt;GPA转换和GPA-&gt;HPA转换之间的依赖关系,<b>一个VM只需要一个nPT</b>,减少了内存开销.如果guest VM中发生了page fault,可直接由guest OS处理,<b>不会产生vm-exit,减少了CPU的开销</b>.可以说,EPT/NPT MMU这种硬件辅助的内存虚拟化技术解决了纯软件实现存在的两个问题.</p><p>因为每次都需要对页基地址进行翻译,所以如果查询guest页表结构为n级,host页表结构为m级,那么翻译页表的gPA就需要n * m次 ,又因为最终获得的gPA还需要通过host页表进行查询,因此最后又需要m次,总计需要 n + nm + m 次访存, 整个过程完全由硬件实现:</p><ul><li>n(guest page walk)</li></ul><ul><li>n * m(翻译所有的页表对应的sPA)</li></ul><ul><li>m (最后一轮翻译gPA)</li></ul><blockquote><p>对于 4 级页表来说就是 24 次</p></blockquote><h2 id="h2-4">参考</h2><ul><li><a href="https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/techpaper/VMware_paravirtualization.pdf" target="_blank">vmware VMware_paravirtualization.pdf</a></li></ul><ul><li><a href="https://www.vmware.com/pdf/Perf_ESX_Intel-EPT-eval.pdf" target="_blank">vmware Perf_ESX_Intel-EPT-eval.pdf</a></li></ul><ul><li><a href="https://blog.csdn.net/hit_shaoqi/article/details/121887459" target="_blank">memory virtualization: shadow page &amp; nest page</a></li></ul><ul><li><a href="https://blog.csdn.net/hx_op/article/details/103980411" target="_blank">内存虚拟化-shadow实现</a></li></ul><ul><li><a href="https://github.com/0voice/Introduce_to_virtualization/blob/main/virtualization_type/memory_virtualization/%E5%86%85%E5%AD%98%E8%99%9A%E6%8B%9F%E5%8C%96.md" target="_blank">Introduce_to_virtualization 内存虚拟化</a></li></ul><ul><li><a href="https://www.cnblogs.com/edver/p/14662609.html" target="_blank">QEMU内存分析(四):ept页表构建</a></li></ul></div>
    <div class="dir-tree"><ul><li><a href="../../md-docs/README" >README</a></li></ul><ul><li><a href="../../md-docs/虚拟化技术" >虚拟化技术</a></li></ul><ul><li><a href="../../md-docs/内存虚拟化" >内存虚拟化</a></li></ul><ul><li><a href="../../md-docs/CPU虚拟化" >CPU虚拟化</a></li></ul><ul><li><a href="../../md-docs/IO虚拟化" >IO虚拟化</a></li></ul><ul><li><a href="../../md-docs/网络虚拟化" >网络虚拟化</a></li></ul><ul><li><a href="../../qemu/intro" >qemu</a><ul><li><a href="../../qemu/intro" >intro</a></li></ul><ul><li><a href="../../qemu/glib" >glib</a></li></ul><ul><li><a href="../../qemu/qom" >qom</a></li></ul><ul><li><a href="../../qemu/system" >system</a></li></ul><ul><li><a href="../../qemu/tcg" >tcg</a></li></ul><ul><li><a href="../../qemu/vhost-user" >vhost-user</a></li></ul><ul><li><a href="../../qemu/EPT" >EPT</a></li></ul><ul><li><a href="../../qemu/machine" >machine</a></li></ul><ul><li><a href="../../qemu/args" >args</a></li></ul><ul><li><a href="../../qemu/contribute" >contribute</a></li></ul><ul><li><a href="../../qemu/ivshmem" >ivshmem</a></li></ul><ul><li><a href="../../qemu/mm" >mm</a></li></ul></li></ul><ul><li><a href="../../kvm/intro" >kvm</a><ul><li><a href="../../kvm/intro" >intro</a></li></ul><ul><li><a href="../../kvm/init" >init</a></li></ul><ul><li><a href="../../kvm/pml" >pml</a></li></ul><ul><li><a href="../../kvm/libvirt" >libvirt</a></li></ul><ul><li><a href="../../kvm/api" >api</a></li></ul><ul><li><a href="../../kvm/ept-trace" >ept-trace</a></li></ul><ul><li><a href="../../kvm/qemu" >qemu</a></li></ul><ul><li><a href="../../kvm/slot" >slot</a></li></ul></li></ul><ul><li><a href="../../cxl/intro" >cxl</a><ul><li><a href="../../cxl/intro" >intro</a></li></ul></li></ul></div>
    <div class="zood"><a class="" href="https://github.com/luzhixing12345/zood" target="_blank">zood</a></div>
    <script type="text/javascript" src="../../../js/next_front.js"></script><script>addLink("../../md-docs/虚拟化技术","../../md-docs/CPU虚拟化","ab");</script><script type="text/javascript" src="../../../js/change_mode.js"></script><script>addChangeModeButton("../../../img/sun.png","../../../img/moon.png");</script><script type="text/javascript" src="../../../js/copy_code.js"></script><script>addCodeCopy("../../../img/clipboard.svg","../../../img/clipboard-check.svg");</script><script type="text/javascript" src="../../../js/navigator.js"></script><script type="text/javascript" src="../../../js/picture_preview.js"></script><script type="text/javascript" src="../../../js/global_js_configuration.js"></script>
</body>

</html>